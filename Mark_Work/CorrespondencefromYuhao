Yes, each weights is a matrix in shape (a,b) where a is the number of neuron if current layer and b is for previous layer. For layerwise update, just use coefficient*self.weight for different layer. For element-wise, I think we should do D*W where D is a diagonal matrix that the element-wise coefficients are placed in diagonal. And W is the weights.

def sgd_with_layerwise_coeff(self, coeff, learning_rate=0.1):
        for i in range(len(self.weights)):
            self.weights[i] -= learning_rate * coeff[i] * self.delta[i].dot(self.activation_outputs[i].T)
            self.baises[i] -= learning_rate * coeff[i] * self.delta[i]

    def sgd_with_elementwise_coeff(self, coeff, learning_rate=0.1):
        for i in range(len(self.weights)):
            self.weights[i] -= learning_rate * np.diag(coeff[i]).dot(self.delta[i].dot(self.activation_outputs[i].T))
            self.baises[i] -= learning_rate * np.diag(coeff[i]).dot(self.delta[i])

It probably is W*D rather than D*W, I'm not quite sure the type and shape of the coefficient.

